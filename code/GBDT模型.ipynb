{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cea4c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import shutil\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal as signal\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, metrics\n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8a17e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 48000*3  ## 表示输入语音的长度，48000表示采样率大小，3表示音频长度大小为3秒，可以根据具体情况进行修改\n",
    "frame_size = 2048 # 每一帧的长度\n",
    "hop_size =512 # 帧移大小\n",
    "\n",
    "def calEnergy(frame):\n",
    "    sumEnergy = 0\n",
    "    for i in frame:\n",
    "        sumEnergy += i**2\n",
    "    return sumEnergy\n",
    "\n",
    "def get_feature(pre_empha_wav, sr=48000):\n",
    "    # 分帧加窗\n",
    "    winfunc = signal.windows.hamming(frame_size)\n",
    "    frames = librosa.util.frame(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, axis=0)\n",
    "    frames = np.array([frame * winfunc for frame in frames])\n",
    "    # mfcc系数\n",
    "    mfccs = librosa.feature.mfcc(y=pre_empha_wav, sr=sr, n_mfcc=24, center=False)\n",
    "    mfccs_scaled_features = np.mean(mfccs.T,axis=0)\n",
    "    # 短时能量\n",
    "    energy = []\n",
    "    for frame in frames:\n",
    "        energy.append(calEnergy(frame))\n",
    "    average_energy = np.average(np.array(energy))\n",
    "    # 短时过零率\n",
    "    zeroCrossingRate = librosa.feature.zero_crossing_rate(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_zcr = np.average(zeroCrossingRate)\n",
    "    # 均方根能量\n",
    "    rmse = librosa.feature.rms(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_rmse = np.average(rmse)\n",
    "    # 频谱质心特征\n",
    "    cent = librosa.feature.spectral_centroid(y=pre_empha_wav, sr=sr, n_fft=frame_size, hop_length=hop_size, center=False)[0] # 计算频谱质心特征\n",
    "    average_cent = np.average(cent)\n",
    "    # 计算二阶频谱带宽，主要是表征与频谱质心位置的偏移程度\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=pre_empha_wav, sr=sr, n_fft=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_spec_bw = np.average(spec_bw)\n",
    "    # 计算声音信号频谱的平整度特征\n",
    "    flatness = librosa.feature.spectral_flatness(y=pre_empha_wav, n_fft=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_flatness = np.average(flatness)\n",
    "    # 滚降系数上限\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=pre_empha_wav, sr=sr, roll_percent=0.99, center=False)[0]\n",
    "    average_rolloff = np.average(rolloff)\n",
    "    # 滚降系数下限\n",
    "    rolloff_min = librosa.feature.spectral_rolloff(y=pre_empha_wav, sr=sr, roll_percent=0.01, center=False)[0]\n",
    "    average_rolloff_min = np.average(rolloff_min)\n",
    "    # 计算六维音调质心特征\n",
    "    y = librosa.effects.harmonic(pre_empha_wav)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr) \n",
    "    average_tonnetz = np.mean(tonnetz.T,axis=0)\n",
    "    return np.hstack((\n",
    "        mfccs_scaled_features, \n",
    "        average_energy, \n",
    "        average_zcr, \n",
    "        average_rmse,\n",
    "        average_cent,\n",
    "        average_spec_bw,\n",
    "        average_flatness,\n",
    "        average_rolloff,\n",
    "        average_rolloff_min,\n",
    "        average_tonnetz\n",
    "    ))\n",
    "\n",
    "def load_audio_file(file_path, input_length=input_length):\n",
    "    data = librosa.core.load(file_path, sr=None)[0] #, sr=None，使用原采样率读取wav音频文件，返回值为wav，sr\n",
    "    if len(data)>input_length:  ## 如果音频的长度较长，则通过随机数的形式确定截取区间的范围        \n",
    "        max_offset = len(data)-input_length      \n",
    "        offset = np.random.randint(max_offset)      \n",
    "        data = data[offset:(input_length+offset)]        \n",
    "    elif len(data)<input_length: ## 如果音频的长度不足，通过随机选择padding的界限，将音频尽量集中到中间部分\n",
    "        if input_length > len(data):\n",
    "            max_offset = input_length - len(data)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0      \n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    else:\n",
    "        pass     \n",
    "    feature = get_feature(data) # 获取log梅尔特征 \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9415e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob(\"G:\\\\GTA_audios\\\\input\\\\audio_train\\\\*.wav\")  # 训练集\n",
    "test_files = glob.glob(\"G:\\\\GTA_audios\\\\input\\\\audio_test\\\\*.wav\")   # 测试集\n",
    "labels = pd.read_excel(\"G:\\\\GTA_audios\\\\dataset.xlsx\") # 训练集的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2626178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建文件标签字典，通过文件名获取对应音频的标签\n",
    "# 先构造单标签映射的字典\n",
    "file_to_label = {\"G:\\\\GTA_audios\\\\input\\\\audio_train\\\\\"+k:v for k,v in zip(labels[\"sample\"].values, labels[\"speed\"].values)}\n",
    "list_labels = sorted(list(set(file_to_label.values()))) ## 将所有训练集样本的标签首先构造集合去重，然后排序\n",
    "label_to_int = {k:v for v,k in enumerate(list_labels)} ## 将每种标签映射到0，1，2……\n",
    "int_to_label = {v:k for k,v in label_to_int.items()} # 反转\n",
    "file_to_int = {k:label_to_int[v] for k,v in file_to_label.items()} # 文件名映射到标签值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4b3e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(file_to_label.keys())\n",
    "train_labels = [label_to_int[x] for x in file_to_label.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4153bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [load_audio_file(x) for x in train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35b4a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = train_labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "eca0688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_label,test_label =sklearn.model_selection.train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    random_state=10,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3614bf",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4f850b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:  训练集：1.0, 测试集：0.4366812227074236\n",
      "epoch 2:  训练集：1.0, 测试集：0.35807860262008734\n",
      "epoch 3:  训练集：1.0, 测试集：0.388646288209607\n",
      "epoch 4:  训练集：1.0, 测试集：0.4672489082969432\n",
      "epoch 5:  训练集：1.0, 测试集：0.4104803493449782\n",
      "epoch 6:  训练集：1.0, 测试集：0.4847161572052402\n",
      "epoch 7:  训练集：1.0, 测试集：0.4759825327510917\n",
      "epoch 8:  训练集：1.0, 测试集：0.4410480349344978\n",
      "epoch 9:  训练集：1.0, 测试集：0.388646288209607\n",
      "epoch 10:  训练集：1.0, 测试集：0.43231441048034935\n",
      "epoch 11:  训练集：1.0, 测试集：0.4148471615720524\n",
      "epoch 12:  训练集：1.0, 测试集：0.47161572052401746\n",
      "epoch 13:  训练集：1.0, 测试集：0.40611353711790393\n",
      "epoch 14:  训练集：1.0, 测试集：0.4148471615720524\n",
      "epoch 15:  训练集：1.0, 测试集：0.42358078602620086\n",
      "epoch 16:  训练集：1.0, 测试集：0.42358078602620086\n",
      "epoch 17:  训练集：1.0, 测试集：0.4192139737991266\n",
      "epoch 18:  训练集：1.0, 测试集：0.42358078602620086\n",
      "epoch 19:  训练集：1.0, 测试集：0.43231441048034935\n",
      "epoch 20:  训练集：1.0, 测试集：0.4410480349344978\n",
      "训练集： 1.0\n",
      "测试集： 0.4847161572052402\n"
     ]
    }
   ],
   "source": [
    "# C=4.1 gamma=0.0025 训练集准确率能够达到61%\n",
    "train_score = 0\n",
    "test_score = 0\n",
    "classifier = svm.SVC(C=4, kernel='rbf', gamma=0.0025, probability=True)\n",
    "for i in range(20):\n",
    "    print(\"epoch %s:\" % (i+1), end='  ')\n",
    "    train_data,test_data,train_label,test_label =sklearn.model_selection.train_test_split(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        random_state=i,\n",
    "        train_size=0.7,\n",
    "        test_size=0.3\n",
    "    )\n",
    "    classifier.fit(train_data, train_label.ravel())\n",
    "    score1 = classifier.score(train_data,train_label)\n",
    "    score2 = classifier.score(test_data,test_label)\n",
    "    print(\"训练集：%s, 测试集：%s\" % (score1, score2))\n",
    "    if score2 > test_score:\n",
    "        train_score = score1\n",
    "        test_score = score2\n",
    "print(\"训练集：\",train_score)\n",
    "print(\"测试集：\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "92543fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 1.0\n",
      "测试集： 0.4410480349344978\n"
     ]
    }
   ],
   "source": [
    "#4.计算svc分类器的准确率\n",
    "print(\"训练集：\",classifier.score(train_data,train_label))\n",
    "print(\"测试集：\",classifier.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0a8cf",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a3ac4e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:  训练集：1.0, 测试集：0.48034934497816595\n",
      "epoch 2:  训练集：1.0, 测试集：0.45414847161572053\n",
      "epoch 3:  训练集：1.0, 测试集：0.4890829694323144\n",
      "epoch 4:  训练集：1.0, 测试集：0.47161572052401746\n",
      "epoch 5:  训练集：1.0, 测试集：0.5065502183406113\n",
      "epoch 6:  训练集：1.0, 测试集：0.49344978165938863\n",
      "epoch 7:  训练集：1.0, 测试集：0.4672489082969432\n",
      "epoch 8:  训练集：1.0, 测试集：0.43231441048034935\n",
      "epoch 9:  训练集：1.0, 测试集：0.5021834061135371\n",
      "epoch 10:  训练集：1.0, 测试集：0.4890829694323144\n",
      "epoch 11:  训练集：1.0, 测试集：0.5065502183406113\n",
      "epoch 12:  训练集：1.0, 测试集：0.5283842794759825\n",
      "epoch 13:  训练集：1.0, 测试集：0.5065502183406113\n",
      "epoch 14:  训练集：1.0, 测试集：0.519650655021834\n",
      "epoch 15:  训练集：1.0, 测试集：0.5240174672489083\n",
      "epoch 16:  训练集：1.0, 测试集：0.5283842794759825\n",
      "epoch 17:  训练集：1.0, 测试集：0.5152838427947598\n",
      "epoch 18:  训练集：1.0, 测试集：0.4759825327510917\n",
      "epoch 19:  训练集：1.0, 测试集：0.462882096069869\n",
      "epoch 20:  训练集：1.0, 测试集：0.537117903930131\n",
      "训练集： 1.0\n",
      "测试集： 0.537117903930131\n"
     ]
    }
   ],
   "source": [
    "train_score = 0\n",
    "test_score = 0\n",
    "gbt = GradientBoostingClassifier(max_depth=6, # 6/14\n",
    "                                    n_estimators=80,\n",
    "                                    learning_rate=0.1,\n",
    "                                    min_samples_leaf=3, # 3\n",
    "                                    min_samples_split=5, # 5/9\n",
    "                                    subsample=0.9)\n",
    "for i in range(20):\n",
    "    print(\"epoch %s:\" % (i+1), end='  ')\n",
    "    train_data,test_data,train_label,test_label =sklearn.model_selection.train_test_split(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        random_state=i,\n",
    "        train_size=0.7,\n",
    "        test_size=0.3\n",
    "    )\n",
    "    gbt.fit(train_data, train_label)\n",
    "    score1 = gbt.score(train_data,train_label)\n",
    "    score2 = gbt.score(test_data,test_label)\n",
    "    print(\"训练集：%s, 测试集：%s\" % (score1, score2))\n",
    "    if score2 > test_score:\n",
    "        train_score = score1\n",
    "        test_score = score2\n",
    "print(\"训练集：\",train_score)\n",
    "print(\"测试集：\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "38d4a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 0.8649155722326454\n",
      "测试集： 0.851528384279476\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集：\",gbt.score(train_data,train_label))\n",
    "print(\"测试集：\",gbt.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "432791d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gbt2.pickle', 'wb')as f:\n",
    "    pickle.dump(gbt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1336104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm.pickle', 'wb')as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8babb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
