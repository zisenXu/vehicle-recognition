{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "151af491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal as signal\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, metrics\n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b94351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers.convolutional import SeparableConv2D, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import tensorflow as tf\n",
    "from keras.metrics import categorical_accuracy\n",
    "from tensorboard.backend.event_processing import event_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20807a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob(\"G:\\\\GTA_audios\\\\input\\\\audio_train\\\\*.wav\")  # 训练集\n",
    "test_files = glob.glob(\"G:\\\\GTA_audios\\\\input\\\\audio_test\\\\*.wav\")   # 测试集\n",
    "labels = pd.read_excel(\"G:\\\\GTA_audios\\\\dataset.xlsx\") # 训练集的标签\n",
    "input_length = 48000*3  ## 表示输入语音的长度，48000表示采样率大小，3表示音频长度大小为3秒，可以根据具体情况进行修改\n",
    "frame_size = 2048 # 每一帧的长度\n",
    "hop_size =512 # 帧移大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ccdc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calEnergy(frame):\n",
    "    sumEnergy = 0\n",
    "    for i in frame:\n",
    "        sumEnergy += i**2\n",
    "    return sumEnergy\n",
    "\n",
    "def get_feature(pre_empha_wav, sr=48000):\n",
    "    # 分帧加窗\n",
    "    winfunc = signal.windows.hamming(frame_size)\n",
    "    frames = librosa.util.frame(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, axis=0)\n",
    "    frames = np.array([frame * winfunc for frame in frames])\n",
    "    # mfcc系数\n",
    "    mfccs = librosa.feature.mfcc(y=pre_empha_wav, sr=sr, n_mfcc=24, center=False)\n",
    "    mfccs_scaled_features = np.mean(mfccs.T,axis=0)\n",
    "    # 短时能量\n",
    "    energy = []\n",
    "    for frame in frames:\n",
    "        energy.append(calEnergy(frame))\n",
    "    average_energy = np.average(np.array(energy))\n",
    "    # 短时过零率\n",
    "    zeroCrossingRate = librosa.feature.zero_crossing_rate(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_zcr = np.average(zeroCrossingRate)\n",
    "    # 均方根能量\n",
    "    rmse = librosa.feature.rms(pre_empha_wav, frame_length=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_rmse = np.average(rmse)\n",
    "    # 频谱质心特征\n",
    "    cent = librosa.feature.spectral_centroid(y=pre_empha_wav, sr=sr, n_fft=frame_size, hop_length=hop_size, center=False)[0] # 计算频谱质心特征\n",
    "    average_cent = np.average(cent)\n",
    "    # 计算二阶频谱带宽，主要是表征与频谱质心位置的偏移程度\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=pre_empha_wav, sr=sr, n_fft=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_spec_bw = np.average(spec_bw)\n",
    "    # 计算声音信号频谱的平整度特征\n",
    "    flatness = librosa.feature.spectral_flatness(y=pre_empha_wav, n_fft=frame_size, hop_length=hop_size, center=False)[0]\n",
    "    average_flatness = np.average(flatness)\n",
    "    # 滚降系数上限\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=pre_empha_wav, sr=sr, roll_percent=0.99, center=False)[0]\n",
    "    average_rolloff = np.average(rolloff)\n",
    "    # 滚降系数下限\n",
    "    rolloff_min = librosa.feature.spectral_rolloff(y=pre_empha_wav, sr=sr, roll_percent=0.01, center=False)[0]\n",
    "    average_rolloff_min = np.average(rolloff_min)\n",
    "    # 计算六维音调质心特征\n",
    "    y = librosa.effects.harmonic(pre_empha_wav)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr) \n",
    "    average_tonnetz = np.mean(tonnetz.T,axis=0)\n",
    "    return np.hstack((\n",
    "        mfccs_scaled_features, \n",
    "        average_energy, \n",
    "        average_zcr, \n",
    "        average_rmse,\n",
    "        average_cent,\n",
    "        average_spec_bw,\n",
    "        average_flatness,\n",
    "        average_rolloff,\n",
    "        average_rolloff_min,\n",
    "        average_tonnetz\n",
    "    ))\n",
    "\n",
    "def get_GBT_features(file_path, input_length=input_length):\n",
    "    data = librosa.core.load(file_path, sr=None)[0] #, sr=None，使用原采样率读取wav音频文件，返回值为wav，sr\n",
    "    if len(data)>input_length:  ## 如果音频的长度较长，则通过随机数的形式确定截取区间的范围        \n",
    "        max_offset = len(data)-input_length      \n",
    "        offset = np.random.randint(max_offset)      \n",
    "        data = data[offset:(input_length+offset)]        \n",
    "    elif len(data)<input_length: ## 如果音频的长度不足，通过随机选择padding的界限，将音频尽量集中到中间部分\n",
    "        if input_length > len(data):\n",
    "            max_offset = input_length - len(data)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0      \n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    else:\n",
    "        pass     \n",
    "    feature = get_feature(data) # 获取log梅尔特征 \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef597538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_features(file_path):\n",
    "    data, fs = soundfile.read(file=file_path)\n",
    "    data = data.T\n",
    "    if len(data)>input_length:  ## 如果音频的长度较长，则通过随机数的形式确定截取区间的范围\n",
    "        max_offset = len(data)-input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:(input_length+offset)]\n",
    "    elif len(data)<input_length: ## 如果音频的长度不足，通过随机选择padding的界限，将音频尽量集中到中间部分\n",
    "        if input_length > len(data):\n",
    "            max_offset = input_length - len(data)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    else:\n",
    "        pass\n",
    "    #Normalize data\n",
    "    mean_value = np.mean(data)\n",
    "    data -= mean_value\n",
    "    max_value = max(abs(data)) + 0.05 #avoid per zero div\n",
    "    data = data/max_value\n",
    "    data = np.reshape(data,[-1,1])\n",
    "    feature_matrix = get_mel_spectrogram(data, fs)\n",
    "    return feature_matrix\n",
    "def get_mel_spectrogram(audio,sr):\n",
    "    eps=2.220446049250313e-16\n",
    "    audio = audio.reshape([1,-1])\n",
    "    ms = int(0.04*sr) #40ms at 44100 Hz\n",
    "    window = scipy.signal.hamming(\n",
    "                                ms,\n",
    "                                sym=False\n",
    "                                )\n",
    "    mel_basis = librosa.filters.mel(sr=sr,\n",
    "                                    n_fft=2048,\n",
    "                                    n_mels=128,\n",
    "                                    htk=False,\n",
    "                                    norm=None\n",
    "                                    )\n",
    "    feature_matrix = np.empty((0,128))\n",
    "    hop_length = int(sr/50)\n",
    "    stft = librosa.stft(audio[0,:]+eps,\n",
    "                            n_fft=2048,\n",
    "                            win_length=ms,\n",
    "                            hop_length=hop_length,\n",
    "                            center=True,\n",
    "                            window=window\n",
    "                            )\n",
    "    # print(\"stft shape : {}\".format(stft.shape))\n",
    "    spectrogram = np.abs(stft)**2\n",
    "    mel_spectrogram = np.dot(mel_basis,spectrogram)\n",
    "    mel_spectrogram = mel_spectrogram.T\n",
    "    mel_spectrogram = np.log10(mel_spectrogram + eps)\n",
    "    feature_matrix = np.append(feature_matrix,mel_spectrogram,axis=0)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4436c2d",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c83cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建文件标签字典，通过文件名获取对应音频的标签\n",
    "# 先构造单标签映射的字典\n",
    "file_to_label = {\"G:\\\\GTA_audios\\\\input\\\\audio_train\\\\\"+k:v for k,v in zip(labels[\"sample\"].values, labels[\"speed\"].values)}\n",
    "list_labels = sorted(list(set(file_to_label.values()))) ## 将所有训练集样本的标签首先构造集合去重，然后排序\n",
    "label_to_int = {k:v for v,k in enumerate(list_labels)} ## 将每种标签映射到0，1，2……\n",
    "int_to_label = {v:k for k,v in label_to_int.items()} # 反转\n",
    "file_to_int = {k:label_to_int[v] for k,v in file_to_label.items()} # 文件名映射到标签值\n",
    "train_files = list(file_to_label.keys())\n",
    "train_labels = [label_to_int[x] for x in file_to_label.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79161b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_features = [get_CNN_features(x) for x in train_files]\n",
    "GBT_features = [get_GBT_features(x) for x in train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e168da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_features = np.array(CNN_features)\n",
    "GBT_features = np.array(GBT_features)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = train_labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "707bbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = np.arange(0,CNN_features.shape[0],1)\n",
    "train_index, test_index, _1, _2 = sklearn.model_selection.train_test_split(x, y, random_state=10, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "57e27f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_test_data = CNN_features[test_index][:,:,:,np.newaxis]\n",
    "GBT_test_data = GBT_features[test_index]\n",
    "test_label = train_labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9163b6",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "088a10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model():\n",
    "    input = layers.Input(shape=(151,128,1))\n",
    "    # First conv layer\n",
    "    c_1 = layers.Conv2D(48,(3,8),padding='same')(input)\n",
    "    c_2 = layers.Conv2D(32,(3,32),padding='same')(input)\n",
    "    c_3 = layers.Conv2D(16,(3,64),padding='same')(input)\n",
    "    c_4 = layers.Conv2D(16,(3,90),padding='same')(input)\n",
    "    conv_1 = layers.Concatenate()([c_1,c_2,c_3,c_4])\n",
    "    x = layers.BatchNormalization()(conv_1)\n",
    "    x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D((5,5))(x)\n",
    "    x = layers.AveragePooling2D((5,5))(x)\n",
    "    # Second conv layer\n",
    "    x = layers.Conv2D(224,5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D((11,4))(x)\n",
    "    x = layers.AveragePooling2D((6,4))(x)\n",
    "    # Output layer\n",
    "    x = layers.Flatten()(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64)(x)\n",
    "    x = layers.Dense(5,activation='softmax')(x)\n",
    "    model = models.Model(input,x)\n",
    "    return model\n",
    "model = gen_model()\n",
    "model.load_weights('model_181-0.65.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af3eaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gbt2.pickle', 'rb')as f:\n",
    "    gbt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f08054f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_score is:0.6601307189542484\n",
      "GBT_score is:0.8300653594771242\n",
      "fusion_score is:0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "CNN_prob = model.predict(CNN_test_data)\n",
    "GBT_prob = gbt.predict_proba(GBT_test_data)\n",
    "total = CNN_test_data.shape[0]\n",
    "CNN_correct = (np.argmax(CNN_prob, axis=1)==test_label).sum()\n",
    "GBT_correct = (np.argmax(GBT_prob, axis=1)==test_label).sum()\n",
    "fusion_correct = (np.argmax((CNN_prob + GBT_prob)/2, axis=1) == test_label).sum()\n",
    "print(\"CNN_score is:%s\" % (CNN_correct/total))\n",
    "print(\"GBT_score is:%s\" % (GBT_correct/total))\n",
    "print(\"fusion_score is:%s\" % (fusion_correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12663ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
